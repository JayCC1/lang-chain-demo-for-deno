{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff586b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage, SystemMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from '@langchain/core/output_parsers';\n",
    "import { load } from \"dotenv\";\n",
    "\n",
    "const env = await load();\n",
    "const process = {\n",
    "  env,\n",
    "};\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  openAIApiKey: process.env.DEEPSEEK_API_KEY, // ✅ 顶层参数\n",
    "  configuration: {\n",
    "    baseURL: \"https://api.deepseek.com/v1\",\n",
    "  },\n",
    "  modelName: \"deepseek-chat\",\n",
    "});\n",
    "\n",
    "// 基础 chain 调用返回的是一个复杂对象\n",
    "// 通过组合 StringOutputParser chain 可以从复杂对象中提取核心字符串输出\n",
    "const outputParser = new StringOutputParser();\n",
    "\n",
    "const simpleChain = chatModel.pipe(outputParser);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 调用模型的多种方式：\n",
    "// - 基础调用\n",
    "// await simpleChain.invoke([\n",
    "//     new HumanMessage(\"Tell me a joke\"),\n",
    "// ]);\n",
    "\n",
    "// - 批量调用\n",
    "// await simpleChain.batch([\n",
    "//     [new HumanMessage(\"Tell me a joke\")],\n",
    "//     [new HumanMessage(\"Hi,who are you?\")],\n",
    "// ]);\n",
    "\n",
    "// - stream 调用，以流式获取响应\n",
    "// 因为 LLM 的很多调用都是一段一段的返回的，\n",
    "// 如果等到完整地内容再返回给用户，就会让用户等待比较久，影响用户的体验\n",
    "// LCEL 开箱就是支持 steaming 流式调用的，基础chain就可使用，不需要单独专门在进行处理\n",
    "// const stream = await simpleChain.stream([\n",
    "//     new HumanMessage(\"Tell me a joke\"),\n",
    "// ]);\n",
    "// for await (const chunk of stream) {\n",
    "//     console.log(chunk);\n",
    "// }\n",
    "\n",
    "// - streamLog 除了像 stream 流一样返回数据，并会返回中间的运行结果\n",
    "// const streamLog = await simpleChain.streamLog([\n",
    "//     new HumanMessage(\"Tell me a joke\"),\n",
    "// ]);\n",
    "// // 每次返回 chunk 的时候，返回完整的对象\n",
    "// for await (const chunk of streamLog) {\n",
    "//     console.log(chunk);\n",
    "// }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
